{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain: Industrial Safety Support - NLP based ChatBot - Safex Pybot Version 1.0 \n",
    "\n",
    "#### Context : \n",
    "\n",
    "**** Great Learning Company is looking forward to design an automation which can interact with the user, understand the problem      and display the resolution procedure \n",
    "\n",
    "**** The company is looking for a designed chatbot utility which can help the professionals to highlight the safety risk as per      the incident description usign a ML or DL or redirect the request to an actual human support executive if the request is        complex or not in its database.\n",
    "\n",
    "#### Data Description : \n",
    "\n",
    "**** The corpus is attached for the reference. Please enhance/add more data to the corpus using your linguistics skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\U6031033\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\U6031033\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "_uuid": "1a10da399a40c2386b7a892db2f725bf2c2a4d91",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open('GL+Bot(1).json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "_uuid": "f5bfc031e0908e044f0bb27ebd1fbf7bac7e66fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 documents\n",
      "14 classes ['employee, polyurethane, pully, installing, impact', 'employee,auxillary,hot,hitting,crane,impact', 'employee,electric,coil,warehouse,forklift,beehive,disturbed,other,people,impact', 'employee,inspect,Jumbo,equipment,esengrasante,toxicity,bottle,impact', 'employee,power,cables,disconnect,industrial,impact', 'escalation', 'greetings', 'mining,Abratech,company,putty,conditioning,tank,impact', 'mining,loosening,trucks,cylindrical,bolt,power,steering,impact', 'mining,mechanical,assistant,crane,descending,ladder,impact', 'mining,moving,oil,cylinder,rail,track,impact,wearing,leather-type,safety,gloves', 'mining,third,remote,employee,sudden,illness,impact', 'rude', 'sendoff']\n",
      "200 unique stemmed words ['15', 'a', 'abratech', 'accid', 'aiml', 'am', 'an', 'and', 'any', 'anyon', 'ar', 'assist', 'at', 'auxil', 'bad', 'batch', 'bear', 'beeh', 'being', 'belong', 'best', 'bloody', 'bolt', 'bot', 'buddy', 'by', 'bye', 'cabl', 'cathod', 'chang', 'coil', 'com', 'company', 'condit', 'contact', 'contamin', 'coupl', 'cran', 'cre', 'cya', 'cylind', 'cylindr', 'day', 'descend', 'detach', 'did', 'disconnect', 'disturb', 'do', 'elect', 'emploey', 'employ', 'equip', 'esengras', 'exc', 'fac', 'first', 'for', 'forklift', 'from', 'glov', 'good', 'goodby', 'gre', 'ham', 'handl', 'hap', 'happend', 'hat', 'hav', 'he', 'hel', 'hello', 'help', 'hey', 'hi', 'hit', 'hot', 'how', 'hum', 'i', 'if', 'il', 'impact', 'in', 'incid', 'indust', 'industry', 'insid', 'inspect', 'instal', 'intak', 'is', 'it', 'jerk', 'jok', 'jumbo', 'lad', 'lat', 'learn', 'leather-type', 'leav', 'liquid', 'list', 'loos', 'lot', 'low', 'lyn', 'machinery', 'mal', 'may', 'me', 'mech', 'min', 'mobl', 'mov', 'my', 'nam', 'no', 'not', 'occ', 'occur', 'of', 'oil', 'on', 'onlin', 'oth', 'party', 'pass', 'peopl', 'person', 'piec', 'plac', 'platform', 'pleas', 'polyureth', 'pow', 'pre-us', 'problem', 'produc', 'protect', 'pul', 'pulley', 'putty', 'rail', 'reason', 'remot', 'remov', 'saf', 'screw', 'see', 'seg', 'shit', 'situ', 'smart', 'socket', 'solv', 'ste', 'stupid', 'sud', 'suff', 'talk', 'tank', 'thank', 'the', 'ther', 'thi', 'think', 'third', 'ticket', 'tim', 'to', 'ton', 'too', 'took', 'tox', 'track', 'tre', 'truck', 'up', 'us', 'useless', 'very', 'wareh', 'was', 'wast', 'wear', 'what', 'wheel', 'when', 'which', 'whil', 'who', 'whos', 'why', 'with', 'work', 'ya', 'yo', 'you']\n"
     ]
    }
   ],
   "source": [
    "# Initialize data fields for our file\n",
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "_uuid": "d402102e6a2fe4b3d3abf6cf36338878c07402f8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U6031033\\AppData\\Local\\Temp/ipykernel_3884/1193693976.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "_uuid": "d9ea1e5769bdd9c92282a502caa47a16db302ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9999  | total loss: \u001b[1m\u001b[32m0.00723\u001b[0m\u001b[0m | time: 0.034s\n",
      "| Adam | epoch: 1000 | loss: 0.00723 - acc: 0.9997 -- iter: 72/80\n",
      "Training Step: 10000  | total loss: \u001b[1m\u001b[32m0.00676\u001b[0m\u001b[0m | time: 0.037s\n",
      "| Adam | epoch: 1000 | loss: 0.00676 - acc: 0.9998 -- iter: 80/80\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\U6031033\\Desktop\\Capstone Project\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 16)\n",
    "net = tflearn.fully_connected(net, 16)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "_uuid": "f3df3637327eb3b2c2a63dfd2c34b1e8ffa135bb",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "_uuid": "da5da061a3b18179176c491d0938412309823cff"
   },
   "outputs": [],
   "source": [
    "# restore all of our data structures\n",
    "import pickle\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "\n",
    "# import our chat-bot intents file\n",
    "import json\n",
    "with open('GL+Bot(1).json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "_uuid": "6dbca05cc97cd1c66896ec00a37bb0f932b02486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\U6031033\\Desktop\\Capstone Project\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "# load our saved model\n",
    "model.load('./model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "_uuid": "0c4c7d32c560284a20da8b659075347f8eee17b5",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# functions for cleansing the sentenses and to get the bag of words\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "_uuid": "4774b1be2f6419c305e36d45c4224452064128d8",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# functions to classify the sentences and for respective responses\n",
    "# create a data structure to hold user context\n",
    "\n",
    "context = {}\n",
    "\n",
    "ERROR_THRESHOLD = 0.25\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "    if results:\n",
    "        # loop as long as there are matches to process\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # set context for this intent if necessary\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: print ('context:', i['context_set'])\n",
    "                        context[userID] = i['context_set']\n",
    "\n",
    "                    # check if this intent is contextual and applies to this user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        if show_details: print ('tag:', i['tag'])\n",
    "                        # a random response from the intent\n",
    "                        return print(random.choice(i['responses']))\n",
    "\n",
    "            results.pop(0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "_uuid": "2d33fdd0ff2fe8ab630ac2f3e51b2518e80ea99d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('greetings', 0.9898449)]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('how are you?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mining,third,remote,employee,sudden,illness,impact', 0.9537687)]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"what happend to the third party remote employee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "_uuid": "cf291929c66e80199c167b130e0016c96eb36a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How may i help you please?\n",
      "\n",
      "Hi there! How may i help you please?\n",
      "\n",
      "Hello! how could i help you?\n",
      "\n",
      "Hello! how could i help you?\n",
      "\n",
      "After throwing the wooden blocks of support of the stabilizer of the Hiab crane truck to the ground, the mechanic assistant was descending from the truck using ladder, he jumped from the last step of the ladder from 69cm, The mechanical assistant jumped from the last step of the ladder and set his left foot on the edge of one of the wooden blocks and got injured on his left ankle, It is an accident at a level of I and its potential level is of IV\n",
      "\n",
      "Please use respectful words\n",
      "\n",
      "Apologies... Tarnsferring the request to our Second Level Team...\n",
      "\n",
      "Apologies... Tarnsferring the request to our Second Level Team...\n",
      "\n",
      "I hope I was able to assist you, Good Bye\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# few tests for the same\n",
    "\n",
    "response('is anyone there?')\n",
    "print()\n",
    "\n",
    "response('is anyone there?')\n",
    "print()\n",
    "\n",
    "response('is anyone there?')\n",
    "print()\n",
    "\n",
    "response('how may i help you?')\n",
    "print()\n",
    "\n",
    "response('what incident occurred to the third party mechanical assistant working in a crane truck?')\n",
    "print()\n",
    "\n",
    "response('what the hell')\n",
    "print()\n",
    "\n",
    "response('you did not help me')\n",
    "print()\n",
    "\n",
    "response('not good solution')\n",
    "print()\n",
    "\n",
    "response('bye')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "_uuid": "be17c3f144b7a63e7613a46ead41300c605bc5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How do you do? How could i help you today?\n",
      "\n",
      "When the employee heated a bearing and hit with the hammer and chisel at one end of the bearing track, a piece of bearing is detached, The employee got a cut on his right thigh and he was transferred to the hospital in an ambulance immediately, Fortunately it is an accident at a level of I and its potential level is of II\n",
      "\n",
      "While the employee was making a disconnection of two power cables of the gate in order to remove it, When the employee was removing the rope tied to the body of gate the warning post was pulled over and it hit the helmet of other employee who was standing at his side, Fortunately it is an accident at a level of I and its potential level is of III\n",
      "\n",
      "When the two employees are preparing to move an oil cylinder on a mobile platform of about 200ks which is mounted on rails, the mobile platform derailed from the rail tracks, both the employees wore leather-type safety gloves and tried to lift the mobile platform and keep it on the rail tracks, while placing the mobile platform on the rail tracks, one of the employee's right hand got trapped between the rail and the mobile platform, At the incident of placing a mobile platform on the rail, the employee's right hand got trapped between the rail and the mobile platform and caused a bruised wound on the index finger of the right hand, fortunately there was no fracture, It is an accident at a level of III and its potential level is of IV\n",
      "\n",
      "Please use respectful words\n",
      "\n",
      "After throwing the wooden blocks of support of the stabilizer of the Hiab crane truck to the ground, the mechanic assistant was descending from the truck using ladder, he jumped from the last step of the ladder from 69cm, The mechanical assistant jumped from the last step of the ladder and set his left foot on the edge of one of the wooden blocks and got injured on his left ankle, It is an accident at a level of I and its potential level is of IV\n",
      "\n",
      "When two workers of the Abratech company were doing putty work inside the conditioning tank, two other employees of the HyT company carried out maneuvers transfer of a pump with the help of a manual tick - which worked hooked to a beam H, dragging the pump on the metal gratings and when trying to release it, the metal grid fell inside the tank, hit a diagonal channel inside the tank, The accident impacted the right arm of one of the workers and rubs the helmet of the second worker that he was crouching, the area where the bomb was being moved was marked with tape and did not have a lookout, It is an accident at a level of I and its potential level is of V\n",
      "\n",
      "Apologies... Tarnsferring the request to our Second Level Team...\n",
      "\n",
      "I hope I was able to assist you, Good Bye\n"
     ]
    }
   ],
   "source": [
    "# we can try some other questions which are given in the project .json file\n",
    "\n",
    "# 1. Start chat session with greetings and ask what the user is looking for.\n",
    "# 2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus.\n",
    "# 3. End the chat session only if the user requests to end else ask what the user is looking for. \n",
    "# Loop continues till the user asks to end it.\n",
    "\n",
    "\n",
    "response('hello')\n",
    "print()\n",
    "response('what is the impact to the employee by accidents of working on a heating bearing and hitting with a hammer?')\n",
    "print()\n",
    "response('what may happen when an employee disconnects the power cables?')\n",
    "print()\n",
    "response('why the employees wearing leather-type safety gloves and placing the mobile platform on the rail track?')\n",
    "print()\n",
    "response('screw you')\n",
    "print()\n",
    "response('who worked on crane truck and descending from the crane using ladder?')\n",
    "print ()\n",
    "response('what is the impact to any person who works for Abratech company?')\n",
    "print()\n",
    "response('you did not help me')\n",
    "print()\n",
    "response('thanks')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#       Start Chatting ver. 1.0          #\n",
      "##########################################\n",
      "you : hi\n",
      "Hello! how could i help you?\n",
      "\n",
      "you : what is the reason for a couple of third party remote employees who is moving an oil cylinder?\n",
      "When the two employees are preparing to move an oil cylinder on a mobile platform of about 200ks which is mounted on rails, the mobile platform derailed from the rail tracks, both the employees wore leather-type safety gloves and tried to lift the mobile platform and keep it on the rail tracks, while placing the mobile platform on the rail tracks, one of the employee's right hand got trapped between the rail and the mobile platform, At the incident of placing a mobile platform on the rail, the employee's right hand got trapped between the rail and the mobile platform and caused a bruised wound on the index finger of the right hand, fortunately there was no fracture, It is an accident at a level of III and its potential level is of IV\n",
      "\n",
      "you : how did the incident happened to the employee whose work is to inspect pre-use of Jumbo 15 equipment? \n",
      "while the employee doing the pre-use inspection of Jumbo 15 equipment, he found a bottle without any label or labelling, he thought that it contains a liquid of mineral water, by mistake, the employee took a small sip of the liquid which is contaminated with an esengrasante product of equipment and machinery of low toxicity and expelled it immediately and washed with enough water and transferred to medical center, Fortunately it is an accident at a level of I and its potential level is of IV\n",
      "\n",
      "you : what is the impact to the employee by accidents of working on a hot bearing and hitting with a hammer?\n",
      "When the employee heated a bearing and hit with the hammer and chisel at one end of the bearing track, a piece of bearing is detached, The employee got a cut on his right thigh and he was transferred to the hospital in an ambulance immediately, Fortunately it is an accident at a level of I and its potential level is of II\n",
      "\n",
      "you : loosening a trucks steering\n",
      "While the employee was workign with a truck's streering cylindrical bolt using power cable and socket, by the force caused by the equipment the bolt suddenly retired, When the employee applied force on the cylindrical bolt to loosen it from the truck's steering it came out of its position and the employee hit his hand agaist the structure of the equipment and had injury to his hand, It is an accident at a level of II and its potential level is of II\n",
      "\n",
      "you : mechanical assistant\n",
      "After throwing the wooden blocks of support of the stabilizer of the Hiab crane truck to the ground, the mechanic assistant was descending from the truck using ladder, he jumped from the last step of the ladder from 69cm, The mechanical assistant jumped from the last step of the ladder and set his left foot on the edge of one of the wooden blocks and got injured on his left ankle, It is an accident at a level of I and its potential level is of IV\n",
      "\n",
      "you : joke\n",
      "Please use respectful words\n",
      "\n",
      "you : did not get any help\n",
      "Apologies... Tarnsferring the request to our Second Level Team...\n",
      "\n",
      "you : bye\n",
      "I hope I was able to assist you, Good Bye\n",
      "\n",
      "you : quit\n"
     ]
    }
   ],
   "source": [
    "# the same can be implemented using interactive mode assuming as a chat bot like below:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"#       Start Chatting ver. 1.0          #\")\n",
    "print(\"##########################################\")\n",
    "\n",
    "\n",
    "stmt = \"\"\n",
    "while stmt != 'q':\n",
    "    stmt  = input(\"you : \")\n",
    "    if stmt == 'quit':\n",
    "        break\n",
    "    else:\n",
    "        response(stmt)\n",
    "        print()\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
